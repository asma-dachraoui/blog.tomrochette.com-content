---
title: Artificial General Intelligence
date: 2015-01-01T13:30:14-05:00
taxonomy:
    type: post
    category: [artificial general intelligence]
---

# Artificial General Intelligence

[TOC]

* Computation/Processing
* Memory
	* Storage
		* Compression
	* Retrieval

-----

To limit the dangers of AI, contain them in a physical body (which can be destroyed).
By extension, this means that human should be able to extend their reach through externalization, that is, provide APIs (function library) of their thought process so that others may query that process.

-----

Concepts are basically numbers
Everything can be represented by a number (basically the concept of primary key -> set of data)
We learn to associate images, sounds, experiences (samples) with a specific concept (number)

-----

# Memory/thinking as a state machine

Memory is the construction of a finite?/nondeterministic? state machine
Thought is the process of going through the state machine
Memory can reconfigure itself based on input

- Reconfigure itself how?
- How often does it reconfigure itself?

In a sense, a state machine with probabilistic paths resembles a neural network
In order to process ideas quickly, the state machine must have a central node with a immense breadth so that it will easily trigger the appropriate path based on the current input. Once the input is processed, the state returns to this central node which awaits further input. This main process is basically consciousness.

-----

DNA is the software of life. If that is true, who wrote the code?
One may extrapolate that the bigbang is similar to the generation of random code and that everything that follows is simply random permutation/mutation of the randomness that ended up into something that is coherent. Like a well programmed neural network, with enough time, randomness will start to generate patterns.

DNA: Transfer/evolution of genetic software

We are an gigantic assembly of billions of cell-sized machines. Each and every cell contains its own copy of the program (DNA) which is itself about 3 billion nucleotides. As there are 4 valid nucleotides/bases, (2^2)^(3*10^9) possible combinations.

-----

If the big bang is true, then we are a simulation. Every thought, action, atom current property is defined in a table at time t = x.

-----

<pre>
<tomzx> well, my understanding of turing so far is that you can represent pretty much anything as a number
<tomzx> except those non-computable numbers
<tomzx> so every word can be represented as a number, phrase (order of words) as a number, documents as a number, thoughts as a number, etc.
<tomzx> basically everything can be labelled
<tomzx> then you can "easily" say A <-> B
<tomzx> in the sense that the entity represented by A is related to the entity represented by B
<tomzx> although I don't think that gets us very far
</pre>

-----

A super-intelligent AI decides that the best use of matter/energy in its vicinity is to nano-engineer the raw materials necessary for its mind to expand. It sends out quadrillions of self-replicating probes in a spherical region, programmed to reduce all matter they encounter into the "smart" matter which the AI can use as its brain. 2500 years later, give or take, there is a massive 5000 light year sphere of "empty" space. It's actually all cognitive matter.

=> is this the reduction to a Turing machine? space is basically just information encoded

-----

# Artificial General Intelligence

The simplest form of initial AGI software would have to be one that rewrite itself.

At the lowest level, computers are governed by a set of instructions, such as ADD, SUB, MUL, DIV, AND, OR, MOV, JMP and other similar instructions.

If we go even a level lower, we can refer to Turing machines, thus the elementary operations are moving left, moving right, reading from the current square on the tape (memory) and writing to the current square.

[A tape for data input/output, a head to read the data, a state register to store working information and and instruction table/program (describes how input data produces output data).]

Thus, the program would have to update itself during execution. However, merely updating the list/sequence of instructions of the program is not a display of intelligence.

The difficulty at this level of abstraction though is that nothing will appear intelligent. Moving left/right while reading and writing symbols on a square cannot display anything that would be qualified as intelligent.

Turing described a couple of instructions that are what I would consider low level intelligence.

First, moving itself is to some degree intelligence. Without movement, change cannot occur (although writing is also a change). *Left/Right movement is equivalent to moving from state A to state B (or to state C) in a state machine.*

Second, reading and writing is the second form of intelligence. Reading allows the agent to learn from the world while writing allows it to communicate with the world.

In itself, this basic machine can do two things:

* I/O with a target
* Change target

---

The list of instruction then become a set of steps the machine will walk through. Those steps ...

---

I believe intelligence emerges from complexity. By stacking simple concepts onto one another, intelligence appears.

-----

Humans learn from imitation. It takes us approximately 1 year to learn to talk. Before that, we learn to make noises, cry to attention, stand up to reach things and so on. Some of those behaviors are guided by imitating other human beings around us.

In the beginning, most of our training is related to motor abilities: how to pick blocks, crawl to our favorite toys, learn to make noise, to speak.

Once this first phase is completed (we've learned their basics and can improve on them), the second aspect we learn to improve is reasoning. Why does this block fit in this hole and not this other hole? Why does this happen when I do that?

-----

If we base ourselves on the fact that machines will use imitation as their first form of learning tool, they will most likely start by integrating existing code into their software.

They'll look through the internet for code they can integrate within themselves. For instance, they'll go onto github and take every piece of code available.

The main issue at this point for them will be to figure out how to integrate this code within their own. They'll also have to figure out what are appropriate inputs/outputs.

They'll want to improve the software they've just obtained. Through static analysis they will be able to determine the exact logic that was used and potentially refactor it using more appropriate instruction and data structures. This means that AGI will become masters of program perfection.

-----

Reading a word is basically triggering letter by letter a sub neural network multiple times until the appropriate word is triggered

for instance, reading "word" would trigger all words with the letter "w", then "wo", then "wor" and finally "word". As the same sub neural network gets activated multiple times, its residual activation keeps increasing as more and more letters of the word are read.

-----

# Things it should do

* Improve algorithms
	* Learn which data structure is the most appropriate for a problem
		* Inspect code and be able to figure out if the current data structure is the best one for its current use
* Improve data structures

# Important properties
* Signal filtering (ignore non-essential data to reduce the domain size)
* Abstraction/simplification/class generation. Learn to group similar stimuli so that you do not have to learn about each of them individually.

-->> Try to map the problem of learning mario to a function optimization problem

How to encode in a neural network avoidance patterns? It's easy to encode in the network what we want it to do, but not what not to do.

-----

How to grow a mind

* Universal data structure framework
* Universal language for representing all these form of structure -> using graphs
