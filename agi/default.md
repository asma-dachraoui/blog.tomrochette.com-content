---
title: Artificial General Intelligence
---

# Artificial General Intelligence

To limit the dangers of AI, contain them in a physical body (which can be destroyed).
By extension, this means that human should be able to extend their reach through externalization, that is, provide APIs (function library) of their thought process so that others may query that process.

-----

Concepts are basically numbers
We learn to associate images, sounds, experiences (samples) with a specific concept (number)

-----

Develop tools to help me develop faster
Develop a system that can improve itself using genetic mutation

-----


Memory is the construction of a finite?/nondeterministic? state machine
Thought is the process of going through the state machine
Memory can reconfigure itself based on input
In a sense, a state machine with probabilistic paths resembles a neural network
In order to process ideas quickly, the state machine must have a central node with a immense breadth so that it will easily trigger the appropriate path based on the current input. Once the input is processed, the state returns to this central node which awaits further input. This main process is basically consciousness.

-----

DNA is the software of life. If that is true, who wrote the code?
One may extrapolate that the bigbang is similar to the generation of random code and that everything that follows is simply random permutation/mutation of the randomness that ended up into something that is coherent. Like a well programmed neural network, with enough time, randomness will start to generate patterns.

-----

If the big bang is true, then we are a simulation. Every thought, action, atom current property is defined in a table at time t = x.

-----

How can AGI/intelligence emerge out of randomness?

-----
Agi philosophy

is it strange to have made something that hates you

-----

DNA: Transfer/evolution of genetic software

We are an gigantic assembly of billions of cell-sized machines. Each and every cell contains its own copy of the program (DNA) which is itself about 3 billion nucleotides. As there are 4 valid nucleotides/bases, (2^2)^(3*10^9) possible combinations.

-----

<pre>
<tomzx> well, my understanding of turing so far is that you can represent pretty much anything as a number
<tomzx> except those non-computable numbers
<tomzx> so every word can be represented as a number, phrase (order of words) as a number, documents as a number, thoughts as a number, etc.
<tomzx> basically everything can be labelled
<tomzx> then you can "easily" say A <-> B
<tomzx> in the sense that the entity represented by A is related to the entity represented by B
<tomzx> although I don't think that gets us very far
</pre>

=> how can we say that an (new) experience B is the same as an already experienced experience B?

-----

A super-intelligent AI decides that the best use of matter/energy in its vicinity is to nano-engineer the raw materials necessary for its mind to expand. It sends out quadrillions of self-replicating probes in a spherical region, programmed to reduce all matter they encounter into the "smart" matter which the AI can use as its brain. 2500 years later, give or take, there is a massive 5000 light year sphere of "empty" space. It's actually all cognitive matter.

=> is this the reduction to a turing machine? space is basically just information encoded

-----

How hard is it for an AI to learn programming languages? Assembly, C, C++, etc.

-----

# Artificial General Intelligence

The simplest form of initial AGI software would have to be one that rewrite itself.

At the lowest level, computers are governed by a set of instructions, such as ADD, SUB, MUL, DIV, AND, OR, MOV, JMP and other similar instructions.

If we go even a level lower, we can refer to Turing machines, thus the elementary operations are moving left, moving right, reading from the current square on the tape (memory) and writing to the current square.

[A tape for data input/output, a head to read the data, a state register to store working information and and instruction table/program (describes how input data produces output data).]

Thus, the program would have to update itself during execution. However, merely updating the list/sequence of instructions of the program is not a display of intelligence.

The difficulty at this level of abstraction though is that nothing will appear intelligent. Moving left/right while reading and writing symbols on a square cannot display anything that would be qualified as intelligent.

Turing described a couple of instructions that are what I would consider low level intelligence.

First, moving itself is to some degree intelligence. Without movement, change cannot occur (although writing is also a change). *Left/Right movement is equivalent to moving from state A to state B (or to state C) in a state machine.*

Second, reading and writing is the second form of intelligence. Reading allows the agent to learn from the world while writing allows it to communicate with the world.

In itself, this basic machine can do two things:

* I/O with a target
* Change target

---

The list of instruction then become a set of steps the machine will walk through. Those steps ...

---

I believe intelligence emerges from complexity. By stacking simple concepts onto one another, intelligence appears.

-----

Humans learn from imitation. It takes us approximately 1 year to learn to talk. Before that, we learn to make noises, cry to attention, stand up to reach things and so on. Some of those behaviors are guided by imitating other human beings around us.

In the beginning, most of our training is related to motor abilities: how to pick blocks, crawl to our favorite toys, learn to make noise, to speak.

Once this first phase is completed (we've learned their basics and can improve on them), the second aspect we learn to improve is reasoning. Why does this block fit in this hole and not this other hole? Why does this happen when I do that?

-----

If we base ourselves on the fact that machines will use imitation as their first form of learning tool, they will most likely start by integrating existing code into their software.

They'll look through the internet for code they can integrate within themselves. For instance, they'll go onto github and take every piece of code available.

The main issue at this point for them will be to figure out how to integrate this code within their own. They'll also have to figure out what are appropriate inputs/outputs.

They'll want to improve the software they've just obtained. Through static analysis they will be able to determine the exact logic that was used and potentially refactor it using more appropriate instruction and data structures. This means that AGI will become masters of program perfection.


-----

# Study of graph architectures
## Properties of interest
* Stability

## Architectures
### Layered
* Easy to do forward/backward propagation

### Fully connected
*  

### Random

-----

# Perfect storage medium
## Properties
* Prevent duplication of data (compression)
* Fast/Instant retrieval (lookup)
* Fast/Instant storage (hashing)

-----

# Things it should do

* Improve algorithms
* Improve data structures

-----

Reading a word is basically triggering letter by letter a sub neural network multiple times until the appropriate word is triggered

for instance, reading "word" would trigger all words with the letter "w", then "wo", then "wor" and finally "word". As the same sub neural network gets activated multiple times, its residual activation keeps increasing as more and more letters of the word are read.

-----

# Mari/o

## Question
* Will it reproduce an already tried genome?
* Is transitivity (a node going to a node then to another node, making the middle node useless) removed?


Genetic evolution is biased toward remembering good neural network while forgetting neural network connections to avoid

## Things to improve
* Reduce the number of attempts that are "stupid"
* Prevent saving a state which is too close to the end

## Things to try
* Use a quadtree approach to learning (1 -> 4 -> 16 squares and so on)
* Add generators (sin/cos/square/triangle)
* Implement save state system
* Make it learn
    * to use the least amount of keys
    * to have the simplest neural network
* Attempt to learn patterns from the neural network (generate/reuse neural network components)
* Synthesize the improvements from all the species of the current generation into the next one
* Like learning an instrument, you need to focus on the parts you have difficulties with. Using the save/load state system, it would save/load states in 5s parts and attempt to improve its best for that part.
* Give an immense penalty to neural network that ends up with a death
* Run the same ~5s segment over 5 generations, then move onto the next 5s segment
    * Divide and conquer approach: 5s, 5s -> 10s (test the first 2 segments together)
* Learn from examples: provide him with a couple of "dumb" but okay examples to learn from
* Compare every generation best neural network against each other from the start/randomly
* Fitness aware online agent (knows it's losing fitness by not moving)

## Things to add (for review purposes)
* Load a specific test (generation/specie/genome)
* Record training time (compare how much time is spent using "from start" vs "from checkpoints")
    * I have some doubt that the "from start" method takes a lot more time but doing so learns more quickly (in the sense of less generations/species), but X minutes of training for both may end up giving one a clear advantage over the other

## Difficult points in level 1
* First enemy
* Bullet + enemy
* High wall
* Slope pipe + enemy

## Metrics to measure
* Rightmost
* Distance traveled
* Score


-->> Compare the advantages of learning from the parts you have difficulties with vs always from the start
* Explore more of the map rapidly
* Even if you are the most retarded, if you have a position advantage, you'll get a +1000 fitness bonus. This means that the real most fit individual will have to be extremely good to compete against your unfair advantage.

13x13 inputs
8 outputs

Am I giving fitness to unfit species simply because they are lucky enough to load a state with an initial higher fitness? Yes and no. Yes, compare to other species under the same generation they are provided with an advantage, but if they end up not providing any benefits over the long run they will be removed from the pool.

# Important properties
* Signal filtering (ignore non-essential data to reduce the domain size)
* Abstraction/simplification/class generation. Learn to group similar stimuli so that you do not have to learn about each of them individually.

-->> Try to map the problem of learning mario to a function optimization problem

How to encode in a neural network avoidance patterns? It's easy to encode in the network what we want it to do, but not what not to do.

-----

Learn which data structure is the most appropriate for a problem
* Inspect code and be able to figure out if the current data structure is the best one for its current use

-----

How to grow a mind

* Universal data structure framework
* Universal language for representing all these form of structure -> using graphs
