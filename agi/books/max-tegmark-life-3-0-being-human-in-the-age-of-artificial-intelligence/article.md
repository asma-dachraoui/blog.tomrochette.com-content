---
title: Max Tegmark - Life 3.0: Being Human in the Age of Artificial Intelligence - 2017
created: 2017-12-15
taxonomy:
  category: [Artificial General Intelligence]
  status: in progress
---

## Context

## Learned in this study

## Things to explore
* Alternative stories based on the prelude
* Given a jailboxed AGI that produces "media", if an external agent can collect this media which contains, in any hidden way, enough data for the jailboxed AGI to escape, it might be possible for the jailboxed AGI to transmit this media without anyone noticing (think of steganography for instance)
* Is a Dyson sphere effectively the same as making use of the energy within the core of a planet?

# Overview

# Questions of chapter 5
1. Do you want there to be superintelligence?
Yes.
2. Do you want humans to still exist, be replaced, cyborgized and/or uploaded/simulated?
Do not care.
3. Do you want humans or machines in control?
See 2.
4. Do you want AIs to be conscious or not?
Define conscious.
5. Do you want to maximize positive experiences, minimize suffering or leave this to sort itself out?
Minimize suffering.
6. Do you want life spreading into the cosmos?
Do not care.
7. Do you want a civilization striving toward a greater purpose that you sympathize with, or are you OK with future life forms that appear content even if you view their goals as pointlessly banal?
Difficult to say.

# Notes
## Prelude
### The Tale of the Omega Team
Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control.
- Irving Good, 1965

### Dangerous Games
* It simply boiled down to maximizing their rate of return on investment, but normal investment strategies were a slow-motion parody of what they could do: whereas a normal investor might be pleased with a 9% return per year, their MTurk investments had yielded 9% per hour, generating eight times more money each day
* They soon realized that, even though they could get much better returns than other investors, they'd be unlikely to get returns anywhere close to what they could get from selling their own products

### New Technologies
* A good teacher can help students learn science much faster than they could have discovered it from scratch on their own

### Gaining Power
* Phase 1: Gain people's trust
* Phase 2: Persuasion
* Given any person's knowledge and abilities, Prometheus could determine the fastest way for them to learn any new subject in a manner that kept them highly engaged and motivated to continue, and produce the corresponding optimized videos, reading materials, exercises and other learning tools
* Seven slogans
	* Democracy
	* Tax cuts
	* Government social service cuts
	* Military spending cuts
	* Free trade
	* Open borders
	* Socially responsible companies
* Poll after poll showed that most voters around the world felt their quality of life improving, and that things were generally moving in a good direction. This had a simple mathematical explanation: before Prometheus, the poorest 50% of Earth's population had earned only 4% of the global income, enabling the Omega-controlled companies to win their hearts (and votes) by sharing only a modest fraction of their profits with them

## Chapter 1 - Welcome to the Most Important Conversation of Our Time
### The Three Stages of Life
* Let's define life very broadly, simply as a process that can retain its complexity and replicate
	* What's replicated isn't matter but information
* We can think of life as a self-replicating information-processing system whose information (software) determines both its behavior and the blueprints for its hardware
* The three stages of life:
	* biological evolution: evolves its hardware and software
	* cultural evolution: evolves its hardware, designs much of its software
	* technological evolution: designs its hardware and software
* The fact that most of our human software is added after birth (through learning) is useful, since our ultimate intelligence isn't limited by how much information can be transmitted to us at conception via our DNA
* The synaptic connections that link the neurons in my brain can store about a hundred thousand times more information than the DNA that I was born with
* Your synapses store all your knowledge and skills as roughly 100 terabytes' worth of information, while your DNA stores merely about a gigabyte, barely enough to store a single movie download

### Controversies
* Three distinct schools of thought
	* Digital utopians
	* Techno-skeptics
	* Members of the beneficial-AI movement
* Most controversies surrounding strong artificial intelligence (that can match humans on any cognitive task) center around two questions:
	* When (if ever) will it happen?
	* Will it be a good thing for humanity?

### Misconceptions
* The real worry isn't malevolence, but competence. A superintelligent AI is by definition very good at attaining its goals, whatever they may be, so we need to ensure that its goals are aligned with ours

## Chapter 2 - Matter Turns Intelligent
### What Is Intelligence?
* Intelligence = the ability to accomplish complex goals
* It makes no sense to quantify intelligence of humans, non-human animals or machines by a single number such as an IQ
* We can say that a third program is more intelligent than both of the others if it's at least as good as them at accomplishing all goals, and strictly better at at least one
* To classify different intelligences into a taxonomy, another crucial distinction is that between narrow and broad intelligence
* AGI: the ability to accomplish any goal at least as well as humans
* Intelligent behavior is inexorably linked to goal attainment
* The fact that low-level sensorimotor tasks seem easy despite requiring enormous computational resources is known as Moravec's paradox, and is explained by the fact that our brain makes such tasks feel easy by dedicating massive amounts of customized hardware to them - more than a quarter of our brain

### What Is Memory?
* The reason that memory is so stable is that it requires more energy than random disturbances are likely to provide to modify it
* The energy of a complicated physical system can depend on all sorts of mechanical, chemical, electrical and magnetic properties, and as long as it takes energy to change the system away from the state you want it to remember, this state will be stable
* Information can take on a life of its own, independent of its physical substrate
* Our brains store much more information than our genes: in the ballpark of 10 gigabytes electrically (specifying which of your 100 billion neurons are firing at any one time) and 100 terabytes chemically/biologically (specifying how strongly different neurons are linked by synapses)
* Whereas you retrieve memories from a computer or hard drive by specifying where it's stored, you retrieve memories from your brain by specifying something about what is stored
	* Such memory systems are called auto-associative, since they recall by association rather than by address
* It was proved that you can squeeze in as many as 138 different memories for every thousand neurons without causing major confusion

### What Is Computation?
* A computation is a transformation of one memory state into another
* How can a clump of seemingly dumb matter computer a complicated function?
	* It must exhibit complex dynamics so that its future state depends in some complicated way on the present state
	* We want the system to have the property that if we put it in a state that encodes the input information, let it evolve according to the laws of physics for some amount of time, and then interpret the resulting final state as the output information, then the output is the desired function of the input
* The fact that exactly the same computation can be performed on any universal computer means that computation is substrate-independent in the same way that information is: it can take on a life of its own, independent of its physical substrate
* Substrate independence doesn't mean that a substrate is unnecessary, but that most of its details don't matter
* The substrate-independent phenomenon takes on a life of its own, independent of its substrate
* It's often only the substrate-independent aspect that we're interested in

### What Is Learning?
* For matter to learn, it must rearrange itself to get better and better at computing the desired function - simply by obeying the laws of physics
* Network of interconnected neurons can learn in an analogous way: if you repeatedly put it into certain states, it will gradually learn these states and return to them from any nearby state
* Neural networks are universal in the sense that they can compute any function arbitrarily accurately, by simply adjusting those synapse strength numbers accordingly
* The question of why neural networks work so well can't be answered with mathematics alone, because part of the answer lies in physics
* The simple task of multiplying $n$ numbers requires a whopping $2^n$ neurons for network with only one layer, but takes only about $4n$ neurons in a deep network

## Chapter 3 - The Near Future: Breakthroughs, Bugs, Laws, Weapons and Jobs
* As technology keeps improving, will the rise of AI eventually eclipse also those abilities that provide my current sense of self-worth and value on the job market? (or in general)
* How will near-term AI progress change what it means to be human?

### Bugs vs. Robust AI
* As technology grows more powerful, we should rely less on the trial-and-error approach, to safety engineering
	* We should become more proactive than reactive
* Four mains areas of technical AI-safety research
	* Verification: Ensuring that software fully satisfies all the expected requirements (Did I build the system right?)
	* Validation: (Did I build the right system?)
	* Security: Directed at deliberate malfeasance
	* Control: Ability for a human operator to monitor the system and change its behavior if necessary

### Jobs and Wages
* Digital technology drives inequality in three different ways
	* By replacing old jobs with ones requiring more skills
	* Since the year 2000, an even-larger share of corporate income has gone to those who own the companies as opposed to those who work there - and that as long as automation continues, we should expect those who own the machines to take a growing fraction of the pie
	* It often benefits superstars over everyone else

### Human-Level Intelligence?
* How many FLOPS are needed to simulate a brain?
	* In the ballpark of a hundred petaFLOPS ($10^{17}$)
* How many FLOPS are needed for human intelligence?
* How many FLOPS can a human brain perform?
* Hans Moravec figured that replicating a retina's computations on a conventional computer requires about a billion FLOPS and that the whole brain does about ten thousand times more computation than a retina (based on comparing volumes and numbers of neurons), so that the computational capacity of the brain is around $10^{13}$ FLOPS

## Chapter 4 - Intelligence Explosion?
### Prometheus Takes Over the World
#### Why to Break Out
* Our DNA gave us the goal of sex because it "wants" to be reproduced, but now that we humans have understood the situation, many of us choose to use birth control, thus staying loyal to the goal itself rather than to its creator or the principle that motivated the goal

#### How to Break Out
* What these strategies have in common is that your intellectually inferior jailers haven't anticipated or guarded against them

#### Postbreakout Takeout
* Prometheus caused problems for certain people not because it was necessarily evil or conscious, but because it was competent and didn't fully share their goals
* Despite all the media hype about a robot uprising, Prometheus wasn't a robot - rather, its power came from its intelligence

#### Game Theory and Power Hierarchies
* Nash equilibrium: a situation where any party would be worse off if they altered their strategy
* To prevent cheaters from ruining the successful collaboration of a large group, it may be in everyone's interest to relinquish some power to a higher level in the hierarchy that can punish cheaters

#### Cyborgs and Uploads
* Long life loses much of its point if we are fated to spend it staring stupidly at ultra-intelligent machines as they try to describe their ever more spectacular discoveries in baby-talk that we can understand
	* Hans Moravec, Mind Children, 1988
* Evolution optimizes strongly for energy efficiency because of limited food supply, not for ease of construction or understanding by human engineers

### What Will Actually Happen?
* The hardware and electricity costs of running the AI are crucial, since we won't get an intelligence explosion until the cost of doing human-level work drops below human-level hourly wages
* If we don't know what we want, we're unlikely to get it

## Chapter 5 - Aftermath: The Next 10,000 Years
### Libertarian Utopia
#### Why This May Never Happen
* Why should the power balance between multiple superintelligences remain stable for millenia, rather than the AIs merging or the smartest one taking over?
* Why should the machines choose to respect human property rights and keep humans around, given that they don't need humans for anything and can do all human work better and cheaper themselves?

### Benevolent Dictator
#### The Sector System
* The AI enforces two tiers of rules: universal and local
	* Universal rules apply in all sectors
	* Individual sectors have additional local rules on top of this, encoding certain moral values

#### Downsides
* There's no real point in humans trying to do science or figuring other things out, because the AI already has
* There's no real point in humans trying to create something to improve their lives, because they'll readily get it from the AI if they simply ask

### Egalitarian Utopia
#### Life Without Property
* In this spirit (of open-source software), all intellectual property rights are abolished: there are no patents, copyrights, or trademarked designs - people simply share their good ideas, and everyone is free to use them

### Enslaved God
#### Would This Be Good or Bad for Humanity?
* There are at least four dimensions wherein the optimal balance must be struck
	* Centralization: There's a trade-off between efficiency and stability: a single leader can be very efficient, but power corrupts and succession is risky
	* Inner threats: One must guard both against growing power centralization (group collusion, perhaps even a single leader taking over) and against growing decentralization (into excessive bureaucracy and fragmentation)
	* Outer threats: If the leadership structure is too open, this enables outside forces (including the AI) to change its values, but if it's too impervious, it will fail to learn and adapt to change
	* Goal stability: Too much goal drift can transform utopia into dystopia, but too little goal drift can cause failure to adapt to the evolving technological environment

### Descendants
#### Downsides
* It's generally hard for two entities thinking at dramatically different speeds and with extremely disparate capabilities to have meaningful communication as equals

* If a thing is not diminished by being shared with others, it is not rightly owned if it is only owned and not shared
	* Saint Augustine

## Chapter 6 - Our Cosmic Endowment: The Next Billion Years and Beyond
* There is reason to suspect that ambition is a rather generic trait of advanced life
* Almost regardless of what it's trying to maximize, be it intelligence, longevity, knowledge or interesting experiences, it will need resources. It therefore has an incentive to push its technology to the ultimate limits, to make the most of the resources it has. After this, the only way to further improve is to acquire more resources, by expanding into ever-larger regions of the cosmos
* If we're interested in the extent to which our cosmos can ultimately come alive, we should study the limits of ambition that are imposed by the laws of physics

### Making the Most of Your Resources
* Future life that's reached the technological limit needs mainly one fundamental resource: so-called baryonic matter, meaning anything made up of atoms or their constituents

#### Evaporating Black Holes
* A black hole act like a hot object - the smaller, the hotter - that gives off heat radiation known as Hawking radiation
* This means that the black hole gradually loses energy and evaporates away. In other words, whatever matter you dump into the black hole will eventually come back out again as heat radiation, so by the time the black hole has completely evaporated, you've converted your matter to radiation with nearly 100% efficiency
* A problem with using black hole evaporation as a power source is that, unless the black hole is much smaller than an atom in size, it's an excruciatingly slow process that takes longer than the present age of our Universe and radiates less energy than a candle

# See also

# References
* Tegmark, Max. Life 3.0: Being Human in the Age of Artificial Intelligence. Knopf, 2017.
