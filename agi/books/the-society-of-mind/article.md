---
title: The Society of Mind
created: 2015-11-15
taxonomy:
  category: [Artificial General Intelligence]
  status: in progress
---

## Context

## Learned in this study

## Things to explore

# Overview

Marvin Minsky's *The Society of Mind* is the epitome of connectionism[^connectionism].

# Thoughts

## Unsorted

* Tasks are executed by low-level, specialized cognitive functions
* The brain is organized hierarchically, where more abstract processes are at the top and low-level functions are at the bottom. In between are *functionalities* that become more and more complex and abstract as they go to the top of the hierarchy
* Higher level functions manage low level functions to ensure they are doing their work properly as well as going in the right direction (doing the *right* thing)
* Higher level functions are competing with one another for resources and being the *main* active process
* Hierarchy of processes
* How are computers different from us?
* They follow instructions
* They don't start things by themselves (do we start things ourselves or if that simply the result of interacting with others?)
* Subconscious -> competing processes that are running in the background

## 7.6 Reinforcement and Reward
* Reward the few moments before success. Works only for short solutions.
* What happens in an architecture with minimal memory? What happens when we gradually increase that memory?
* Only able to execute parts of a big loop
* Procedures encoded as part of a speciesâ€™ genes

## 7.7 Local Responsibility
* Global vs local reward policy/scheme
* Global reward leads to slower learning

## 7.10 Genius
* Genius: knows how to manage what he learns
* Learn to rearrange how to think
* Learn better ways to learn to learn

## 8.1 K-lines: A Theory of Memory
* Tag all the tools that helped you solve a problem
* How do you know which tools to use? Won't you end up taking too many tools? Is it then a question of removing tags from tools that did not contribute to the solution?
* Tags = fragments of ideas

# Notes

## 7.3 The Puzzle Principle
**Puzzle Principle:** We can program a computer to solve anyt problem by trial and error, without knowing how to solve it in advance, provided only that we have a way to recognize the problem is solved.

## 7.4 Problem Solving
**The Progress Principle:** Any process of exhaustive search can be greatly reduced if we possess some way to detect when "progress" has been made. Then we can trace a path toward a solution, just as a person can climb an unfamiliar hill in the dark - by feeling around, at every step, to find the direction of steepest ascent.

**Goals and Subgoals.** The most powerful way we know for discoverying how to solve a hard problem is to find a method that splits it into several simpler ones, each of which can be solved separately.

**Using Knowledge.** The most efficient way to solve a problem is to already know how to solve it. Then one can avoid search entirely.

## 8.1 K-lines: A Theory of Memory
* How is knowledge represented?
* How is it stored?
* How is it retrieved?
* Then, how is it used?

## 17.6 Prerequisites for Growth
* One reason a skill may grow in steps is that it needs "prerequisites"
	* Some processes cannot be learned until certain other processes become available
* Many of Piaget's theories were based on his suspicion that certain concepts had prerequisites

## 17.8 Attachment-Images
* **The Oedipus complex:** rejecting one of the two parent models in order to simplify value-model learning.

## 17.9 Different Spans of Memories
* Parent-to-child and child-to-parents bonds based on certain types of memory
* The child (animals) learns through "impriting" to recognize their parents
* The parents (animals) reject children with which they were not involved in bonding shortly after birty; it's an evolutionary disadvantage to raise the offspring of unrelated individuals
* Individuals either bond with a mate "for life" or to certain constant prototypes

## 17.10 Intellectual Trauma
* *I simply can't. I'm just no good at that.*
	* A learned way to avoid the shame and stress that came from social censure of failures in the past
	* It might also be a reaction to the nonsocial sterss that came from having been unable to deal with certain ideas

## 18.1 Must Machines Be Logical?
* A logical system without a goal will merely generate an endless host of pointless truths

## 18.5 Strong Arguments
* Use several different arguments to prove the same point by putting them "in parallel"
* A chain (of arguments) can break with any single injury, but a parallel bundle cannot fail unless every one of its links has been broken

## 18.6 Magnitude from Multitude
**Strength from Magnitude:** When two forces work together, they add to form a single larger force. But when two forces oppose each other directly, their strengths subtract.

**Strength from Multitude:** The more reasons we can find in favor of a particular decision, the more confidence we can have in it. This is because if some of those reasons turn out to be wrong, other reasons may still remain.

## 18.7 What is a Number?
* Every concept is part of a huge network
* Meaning is derived from the network upon which it is built
	* Different for each individual

## 18.8 Mathematics Made Hard
* The more cross-connected our common-sense ideas are, the more useful they're likely to be

## 18.9 Robustness and Recovery
**Duplication:** Duplicate functionality so that if some part of the agents duplicating this functionality are lost, the others can take over.
**Self-Repair:** Be able to repair a faulty section if needed.
**Distributed Processes:** Distribute the function over many area, such that if a portition is destroyed, not all of it is destroyed.
**Accumulation:** Work is based on previous experience, such that if newer experience is lost, we can still proceed from older experience.

## 19.1 The Roots of Intention
* Words are like notes, alone they're not much, but together they form sentences, and thus meaning
* Where do intentions come from? What do they emerge from?

## 19.3 Wordes and Ideas
* Polynemes are similar to neural networks which are encapsulated in their own little black box
	* Such black box might be called "Color", "Shape", "Smell", "Taste", etc.
	* When a signal is received by the black box, it will configure itself to output a specific signal ("Color" -> "red", "Shape" => "round", etc.)
* Isonomes are short-term memory controls for other agencies

## 19.4 Objects and Properties
* A property is something that does not change capriciously (often)
* The most useful sets of properties those whose members do not interact too much (orthogonal)

## 19.5 Polynemes
* Each agency must learn its own specific and appropriate response. Each agency must have its private dictionary or memory bank to tell it how to respond to every polyneme (Chinese room?) 

## 19.6 Recognizers
* The simplest way to recognize something is to verify that it has certain properties
* Often times it is not possible to verify that all properties are present, thus we might use a system that "looks for evidence" (x out of y properties to become active)
	* This system has many issues (identifying objects improperly, unable to attain identification threshold, etc.)
	* One also has to verify their dimensions and relationships

## 19.7 Weighing evidence
* Recognizers start to look **a lot** like neural networks (inputs + weights + output)
* Introduction of the perceptron
* Perceptrons are unable to take into account enough of the relations among various features

## 19.9 Recognizing Thoughts
* Within the brain, various forms of inputs can lead to the same "final signal", in other words the same thought generated from seeing an apple or being told "thing about an apple"

## 19.10 Closing the Ring
* If enough recognition-agent are aroused to trigger a polyneme, that polyneme may in turn activate related sensors/K-lines in other agencies.
	* In other words, if you start with enough clues to arouse one of your apple-nemes, it will automatically arouse memories of the other properties and qualities of apples and create a more complete impression, "simulus", or hallucination of the experience of seeing, feeling, and even of eating an apple.
* This could be called *reminding*

## 20.4 Locking-in and Weeding-out
* To use the power of language, one must acquire many different ways to understand

## 20.8 Connection lines
* Bus-like arrangement between transmitting-agents and receiving-agents
* Transmitting-agents excite n wires on the bus
* Receiving-agents are and-gates and will only activate upon the right combination of activations (1 wire per required wire signal)
* The disadvantage of a bus-like design is that it can transmit only one signal at a time

## 21.3 Trans-frames
* Conceptual dependencies:
	* P-Trans: act on location (move, go)
	* M-Trans: represents mental acts (tell)
	* A-Trans: represents a transfer (give, take)
* https://en.wikipedia.org/wiki/Conceptual_dependency_theory
* Similar to the concept of transitivity

# See also

# Sources

* Minsky, Marvin Lee. The Society of Mind. New York: Simon and Schuster, 1986.
* http://www.amazon.com/The-Society-Mind-Marvin-Minsky/dp/0671657135

[^connectionism]: https://en.wikipedia.org/wiki/Connectionism